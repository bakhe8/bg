import pandas as pd
import json
import sys
import os
import argparse
from datetime import datetime
import warnings

# ÙƒØªÙ… ØªØ­Ø°ÙŠØ±Ø§Øª pandas ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
warnings.filterwarnings('ignore')

class ExcelToJsonConverter:
    def __init__(self, clean_data=True, optimize_memory=True):
        self.supported_formats = ['.xlsx', '.xls']
        self.clean_data = clean_data
        self.optimize_memory = optimize_memory
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        self.check_dependencies()
    
    def check_dependencies(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        try:
            import pandas
            import openpyxl
        except ImportError as e:
            print("âŒ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…Ø«Ø¨ØªØ©!")
            print("ğŸ“¦ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØªÙ‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
            print("   pip install pandas openpyxl")
            sys.exit(1)
    
    def validate_file(self, file_path):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù ÙˆØµÙŠØºØªÙ‡"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù '{file_path}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        
        file_ext = os.path.splitext(file_path)[1].lower()
        if file_ext not in self.supported_formats:
            raise ValueError(f"Ø§Ù„ØµÙŠØºØ© '{file_ext}' ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©. Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: {self.supported_formats}")
        
        return True
    
    def read_excel_optimized(self, file_path, sheet_name=0):
        """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel Ø¨Ø·Ø±Ù‚ Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡
            read_options = {
                'sheet_name': sheet_name,
                'keep_default_na': False,  # Ø¹Ø¯Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ø¥Ù„Ù‰ NaN
                'na_values': ['', ' ', 'NULL', 'null'],  # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ØªÙŠ ØªØ¹ØªØ¨Ø± ÙØ§Ø±ØºØ©
            }
            
            if self.optimize_memory:
                read_options.update({
                    'dtype': str,  # Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ Ø´ÙŠØ¡ ÙƒÙ†Øµ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
                    'usecols': None,  # Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ù‚Ø±Ø§Ø¡Ø© Ø£Ø¹Ù…Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø©)
                })
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if sheet_name == "all":
                read_options["sheet_name"] = None
            else:
                read_options["sheet_name"] = sheet_name
            return pd.read_excel(file_path, **read_options)
                
        except ImportError as e:
            raise ImportError(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª: {e}")
        except Exception as e:
            raise Exception(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
    
    def clean_data_smart(self, df):
        """ØªÙ†Ø¸ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠÙƒÙ„"""
        if not self.clean_data:
            return df
            
        df_clean = df.copy()
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù†ØªÙ‚Ø§Ø¦ÙŠ - Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªÙƒÙˆÙ† ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹ ÙÙ‚Ø·
        initial_rows = len(df_clean)
        df_clean = df_clean.dropna(how='all')
        removed_rows = initial_rows - len(df_clean)
        
        if removed_rows > 0:
            print(f"   ğŸ§¹ ØªÙ… Ø¥Ø²Ø§Ù„Ø© {removed_rows} ØµÙ ÙØ§Ø±Øº ØªÙ…Ø§Ù…Ø§Ù‹")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·
        text_columns = df_clean.select_dtypes(include=['object']).columns
        for col in text_columns:
            df_clean[col] = df_clean[col].apply(
                lambda x: x.strip() if isinstance(x, str) else x
            )
        
        return df_clean
    
    def detect_data_types_improved(self, df):
        """ÙƒØ´Ù Ù…Ø­Ø³Ù† Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø®Ø§ØµØ©"""
        data_types = {}
        mixed_types = {}
        
        for col in df.columns:
            if df[col].empty:
                data_types[col] = {"type": "empty", "sample": ""}
                continue
            
            # Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© ØµØºÙŠØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„
            sample_size = min(10, len(df[col]))
            sample_data = df[col].iloc[:sample_size].tolist()
            
            # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ¹Ù…Ù‚ Ù„Ù„Ø¹Ù…ÙˆØ¯
            col_analysis = self.analyze_column(df[col], sample_data)
            data_types[col] = col_analysis
            
            # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©
            if col_analysis.get('mixed_types', False):
                mixed_types[col] = col_analysis
        
        if mixed_types:
            print("   âš ï¸  ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø£Ù†ÙˆØ§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØªÙ„Ø·Ø©:")
            for col, info in mixed_types.items():
                print(f"     - {col}: {info['types_found']}")
        
        return data_types
    
    def analyze_column(self, series, sample_data):
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ù…Ù‚ Ù„Ù„Ø¹Ù…ÙˆØ¯"""
        non_empty = series.dropna()
        if non_empty.empty:
            return {"type": "empty", "sample": ""}
        
        # Ø§ÙƒØªØ´Ø§Ù Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯
        types_found = set()
        numeric_count = 0
        text_count = 0
        date_count = 0
        
        for item in sample_data:
            if pd.isna(item) or item == '':
                continue
                
            if self.is_numeric_string(item):
                types_found.add("numeric_string")
                numeric_count += 1
            elif self.is_potential_date(item):
                types_found.add("date_like")
                date_count += 1
            else:
                types_found.add("text")
                text_count += 1
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¦Ø¯
        total_non_empty = len([x for x in sample_data if x != ''])
        if not total_non_empty:
            return {"type": "empty", "sample": ""}
        
        # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙƒÙ†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ØµÙØ§Ø± Ø¨Ø§Ø¯Ø¦Ø©
        if "numeric_string" in types_found and any(
            str(item).startswith('0') and len(str(item)) > 1 
            for item in sample_data if item != ''
        ):
            final_type = "text_preserve_format"  # Ù†Øµ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        elif len(types_found) == 1:
            final_type = list(types_found)[0]
        else:
            final_type = "mixed"
        
        sample_value = sample_data[0] if sample_data else ""
        if pd.isna(sample_value):
            sample_value = ""

        return {
            "type": final_type,
            "types_found": list(types_found),
            "sample": sample_value,
            "numeric_ratio": numeric_count / total_non_empty,
            "text_ratio": text_count / total_non_empty,
            "mixed_types": len(types_found) > 1
        }
    
    def is_numeric_string(self, value):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø±Ù‚Ù…Ø§Ù‹"""
        if isinstance(value, (int, float)):
            return True
        if isinstance(value, str):
            try:
                float(value.replace(',', ''))
                return True
            except ValueError:
                return False
        return False
    
    def is_potential_date(self, value):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† ØªØ§Ø±ÙŠØ®"""
        if isinstance(value, (pd.Timestamp, datetime)):
            return True
        if isinstance(value, str):
            date_patterns = ['-', '/', ':', '202', '199']  # Ø£Ù†Ù…Ø§Ø· ØªÙˆØ§Ø±ÙŠØ® Ø´Ø§Ø¦Ø¹Ø©
            return any(pattern in value for pattern in date_patterns)
        return False
    
    def convert_excel_to_json(self, excel_file, sheet_name=0, output_file=None):
        """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…Ø­Ø¯Ø¯Ø©"""
        try:
            print(f"ğŸ“– Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {excel_file}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù
            self.validate_file(excel_file)
            
            # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø³Ù†Ø©
            data = self.read_excel_optimized(excel_file, sheet_name)
            
            if sheet_name == "all":
                return self.process_multiple_sheets(data, excel_file, output_file)
            else:
                return self.process_single_sheet(data, excel_file, sheet_name, output_file)
            
        except FileNotFoundError as e:
            raise e
        except ImportError as e:
            raise e
        except pd.errors.EmptyDataError:
            raise Exception("Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª")
        except pd.errors.ParserError as e:
            raise Exception(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
        except Exception as e:
            raise Exception(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
    
    def process_single_sheet(self, df, excel_file, sheet_name, output_file):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ±Ù‚Ø© Ù…ÙØ±Ø¯Ø©"""
        print(f"   ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ÙˆØ±Ù‚Ø©: {sheet_name}")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø°Ø§ Ù…Ø·Ù„ÙˆØ¨)
        if self.clean_data:
            df_processed = self.clean_data_smart(df)
        else:
            df_processed = df
        
        # ÙƒØ´Ù Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_types = self.detect_data_types_improved(df_processed)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        result_data = {
            "file_info": {
                "file_name": os.path.basename(excel_file),
                "sheet_name": sheet_name,
                "conversion_date": datetime.now().isoformat(),
                "records_count": len(df_processed),
                "columns_count": len(df_processed.columns),
                "cleaning_applied": self.clean_data
            },
            "data_types": data_types,
            "columns": list(df_processed.columns),
            "records": self.prepare_records(df_processed, data_types)
        }
        
        return self.save_output(result_data, output_file)
    
    def process_multiple_sheets(self, data_dict, excel_file, output_file):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙˆØ±Ø§Ù‚ Ù…ØªØ¹Ø¯Ø¯Ø©"""
        all_sheets_data = {}
        
        for sheet_name, df in data_dict.items():
            print(f"   ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ±Ù‚Ø©: {sheet_name}")
            
            if self.clean_data:
                df_clean = self.clean_data_smart(df)
            else:
                df_clean = df
            
            data_types = self.detect_data_types_improved(df_clean)
            
            all_sheets_data[sheet_name] = {
                "metadata": {
                    "records_count": len(df_clean),
                    "columns_count": len(df_clean.columns),
                    "cleaning_applied": self.clean_data
                },
                "data_types": data_types,
                "records": self.prepare_records(df_clean, data_types)
            }
        
        result_data = {
            "file_info": {
                "file_name": os.path.basename(excel_file),
                "conversion_date": datetime.now().isoformat(),
                "total_sheets": len(data_dict),
                "cleaning_applied": self.clean_data
            },
            "sheets": all_sheets_data
        }
        
        return self.save_output(result_data, output_file)
    
    def prepare_records(self, df, data_types):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚"""
        records = []
        for _, row in df.iterrows():
            record = {}
            for col in df.columns:
                value = row[col]
                if pd.isna(value):
                    record[col] = None
                    continue
                
                # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù„Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù†ØµÙŠØ©
                col_info = data_types.get(col, {})
                if col_info.get('type') == 'text_preserve_format' and value != '':
                    record[col] = str(value)  # Ø§Ù„Ø­ÙØ§Ø¸ ÙƒÙ†Øµ
                else:
                    record[col] = value
            records.append(record)
        return records
    
    def save_output(self, result_data, output_file):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª"""
        json_output = json.dumps(
            result_data,
            ensure_ascii=False,
            indent=2,
            default=str,
            allow_nan=False,
        )
        
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(json_output)
                print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_file}")
            except IOError as e:
                raise Exception(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {e}")
        
        return json_output

def setup_argparse():
    """Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù…Ø¹ argparse"""
    parser = argparse.ArgumentParser(
        description='Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªØ­ÙˆÙŠÙ„ Excel Ø¥Ù„Ù‰ JSON',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Ø£Ù…Ø«Ù„Ø©:
  %(prog)s data.xlsx                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
  %(prog)s data.xlsx --sheet all        # ØªØ­ÙˆÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚
  %(prog)s data.xlsx --no-clean         # Ø¨Ø¯ÙˆÙ† ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  %(prog)s data.xlsx -o output.json     # ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        '''
    )
    
    parser.add_argument('file', help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Excel Ø§Ù„Ù…Ø¯Ø®Ù„')
    parser.add_argument('--sheet', default=0, help='Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© Ø£Ùˆ "all" Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ø§Ù„Ø£ÙˆÙ„Ù‰)')
    parser.add_argument('-o', '--output', help='Ù…Ù„Ù JSON Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)')
    parser.add_argument('--no-clean', action='store_true', help='ØªØ¹Ø·ÙŠÙ„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
    parser.add_argument('--no-optimize', action='store_true', help='ØªØ¹Ø·ÙŠÙ„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©')
    
    return parser

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬"""
    parser = setup_argparse()
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù…Ù† Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø£ÙˆÙ„Ø§Ù‹
    if len(sys.argv) > 1:
        args = parser.parse_args()
        
        converter = ExcelToJsonConverter(
            clean_data=not args.no_clean,
            optimize_memory=not args.no_optimize
        )
        
        try:
            result = converter.convert_excel_to_json(
                args.file,
                args.sheet,
                args.output
            )
            
            data = json.loads(result)
            if "sheets" in data:
                total_records = sum(sheet["metadata"]["records_count"] for sheet in data["sheets"].values())
                print(f"âœ… ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­: {len(data['sheets'])} Ø£ÙˆØ±Ø§Ù‚ØŒ {total_records} Ø³Ø¬Ù„")
            else:
                print(f"âœ… ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­: {data['file_info']['records_count']} Ø³Ø¬Ù„")
                
        except Exception as e:
            print(f"âŒ {e}")
            sys.exit(1)
    
    else:
        # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
        print("ğŸ”„ Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªØ­ÙˆÙŠÙ„ Excel Ø¥Ù„Ù‰ JSON")
        print("=" * 50)
        
        converter = ExcelToJsonConverter()
        
        try:
            excel_file = input("ğŸ“ Ø£Ø¯Ø®Ù„ Ù…Ø³Ø§Ø± Ù…Ù„Ù Excel: ").strip()
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… parser Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚
            args = parser.parse_args([excel_file] + sys.argv[1:])
            
            # Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
            sheet_names = converter.get_sheet_names(excel_file) if hasattr(converter, 'get_sheet_names') else []
            
            if sheet_names and len(sheet_names) > 1:
                print(f"\nğŸ“‘ Ø§Ø®ØªØ± Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­ÙˆÙŠÙ„Ù‡Ø§:")
                print("   all - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚")
                for sheet in sheet_names:
                    print(f"   {sheet}")
                
                sheet_choice = input("   Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ: all): ").strip()
                args.sheet = sheet_choice if sheet_choice else "all"
            else:
                args.sheet = sheet_names[0] if sheet_names else 0
            
            if not args.output:
                base_name = os.path.splitext(excel_file)[0]
                args.output = input(f"ğŸ’¾ Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: {base_name}.json): ").strip()
                if not args.output:
                    args.output = f"{base_name}.json"
            
            # Ø§Ù„ØªØ­ÙˆÙŠÙ„
            result = converter.convert_excel_to_json(args.file, args.sheet, args.output)
            
            if result:
                data = json.loads(result)
                if "sheets" in data:
                    total_records = sum(sheet["metadata"]["records_count"] for sheet in data["sheets"].values())
                    print(f"âœ… ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­: {len(data['sheets'])} Ø£ÙˆØ±Ø§Ù‚ØŒ {total_records} Ø³Ø¬Ù„")
                else:
                    print(f"âœ… ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­: {data['file_info']['records_count']} Ø³Ø¬Ù„")
                    
        except Exception as e:
            print(f"âŒ {e}")
            sys.exit(1)

if __name__ == "__main__":
    main()
